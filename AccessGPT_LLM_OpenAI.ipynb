{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Practical Demo on How to Access and Utilize ChatGPT via OpenAI's API\n",
        "\n",
        "#### Step 1: Understanding OpenAI's Platform\n",
        "* Models Overview: Access detailed model information here (https://platform.openai.com/docs/models/gpt-3)\n",
        "* API Overview: Comprehensive guide available here (https://platform.openai.com/docs/overview)\n",
        "* Tokenizer Tool:\n",
        "  * Useful for encoding texts; try it here (https://platform.openai.com/tokenizer)\n",
        "  * Understanding Tokens\n",
        "    * Approximate conversion: 1 token ≈ 4 characters or 0.75 words\n",
        "    * Token pricing details here (https://openai.com/api/pricing/)\n",
        "\n",
        "#### Step 2: Signing Up and API Keys\n",
        "* Create an Account: Register at OpenAI’s official website (https://openai.com/api/)\n",
        "* Subscription Plans: Explore various pricing plans here (https://openai.com/api/pricing/)\n",
        "* Obtain API Keys: Secure your API key and it is important for all API requests\n",
        "\n",
        "#### Step 3: Practical API Usage\n",
        "* Model Selection (https://platform.openai.com/docs/models/); Example: \"gpt-3.5-turbo-0125\" for question answer tasks\n",
        "* Parameters for API Calls: Customize request with max_tokens, temperature, top_p for custom response\n",
        "\n",
        "#### Step 4: Example API Call\n",
        "* Example: Encoding \"You are great!\" results in four tokens: [\"You\", \"are\", \"great\", \"!\"]\n",
        "* Model: GPT-3.5 Turbo is a fast and cost-effective for simple tasks\n",
        "* Practical Demo: How to set up and make an API call using Python to interact with ChatGPT (gpt-3.5-turbo-0125)\n",
        "\n"
      ],
      "metadata": {
        "id": "Yds8V5vPLgc1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#installing library\n",
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkgBMBwBTRLK",
        "outputId": "3d42fff8-0b46-4234-d8a8-8c5dec0eee81"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.33.0-py3-none-any.whl (325 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/325.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/325.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.5/325.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m703.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.33.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "#accessing OpenAI API key\n",
        "import os\n",
        "client = OpenAI(api_key='sk-------------------')"
      ],
      "metadata": {
        "id": "_jWJIlN-Twj9"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calling API\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo-0125\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Who was a President of the European Commission?\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"The person is longest-serving President of the European Commission.\"}\n",
        "  ]\n",
        ")"
      ],
      "metadata": {
        "id": "wKJkamaUU1QU"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#example\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQ52qSSOfoGc",
        "outputId": "5d78a12c-07d7-4f54-fc70-634d4f382151"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The longest-serving President of the European Commission was Jacques Delors, who served from 1985 to 1995.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#adding three more parameters in the API call\n",
        " # 1. max_token (it sets the max number of tokens in the response),\n",
        " # 2. temperature (it controls the creativity of the response) and\n",
        " # 3. top_p (limits the token choices to the top 90% of probability)\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo-0125\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Who was a President of the European Commission?\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"The person is longest-serving President of the European Commission.\"},\n",
        "  ],\n",
        "  max_tokens=45,\n",
        "  temperature=0.8,\n",
        "  top_p=0.8\n",
        "  )"
      ],
      "metadata": {
        "id": "5yxpRx0jg9g-"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#example\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KckqgXyChEQG",
        "outputId": "30446961-342f-4cb2-8d7b-753fe4058e66"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The longest-serving President of the European Commission was Jacques Delors, who served from 1985 to 1995.\n"
          ]
        }
      ]
    }
  ]
}